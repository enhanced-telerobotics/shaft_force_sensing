[rank: 0] Seed set to 1
  0%|          | 0/13 [00:00<?, ?it/s]  8%|â–Š         | 1/13 [00:00<00:08,  1.39it/s] 15%|â–ˆâ–Œ        | 2/13 [00:01<00:06,  1.60it/s] 23%|â–ˆâ–ˆâ–       | 3/13 [00:01<00:05,  1.85it/s] 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:02<00:04,  1.98it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:02<00:03,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:03<00:03,  2.13it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:03<00:02,  2.17it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:03<00:02,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:04<00:02,  1.82it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:05<00:01,  1.61it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:06<00:01,  1.51it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:07<00:00,  1.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.66it/s]
  0%|          | 0/13 [00:00<?, ?it/s]  8%|â–Š         | 1/13 [00:00<00:06,  1.71it/s] 15%|â–ˆâ–Œ        | 2/13 [00:00<00:04,  2.22it/s] 23%|â–ˆâ–ˆâ–       | 3/13 [00:01<00:04,  2.46it/s] 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:01<00:03,  2.58it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:02<00:03,  2.66it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:02<00:02,  2.71it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:02<00:02,  2.72it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:03<00:01,  2.74it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:03<00:01,  2.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:04<00:01,  2.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:04<00:01,  1.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:05<00:00,  1.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  1.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.19it/s]
/home/sxk2514/.conda/envs/ltc311/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/sxk2514/erie/shaft_force_sensing/shaft_force_s ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sxk2514/.conda/envs/ltc311/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /scratch/pioneer/users/sxk2514/shaft_force_sensing/logs/20260216_113442 exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type     | Params | Mode  | FLOPs
-----------------------------------------------------
0 | loss_fn | MSELoss  | 0      | train | 0    
1 | model   | LTCModel | 25.5 K | train | 0    
-----------------------------------------------------
20.5 K    Trainable params
5.1 K     Non-trainable params
25.5 K    Total params
0.102     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
0         Total Flops
/home/sxk2514/.conda/envs/ltc311/lib/python3.11/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
/home/sxk2514/.conda/envs/ltc311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
/home/sxk2514/.conda/envs/ltc311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Metric val/loss_epoch improved. New best score: 1.104
Epoch 0, global step 1305: 'val/loss_epoch' reached 1.10447 (best 1.10447), saving model to '/scratch/pioneer/users/sxk2514/shaft_force_sensing/logs/20260216_113442/best-epoch=00-loss=1.1045.ckpt' as top 1
[2026-02-16T11:44:14.894] error: *** JOB 3144606 ON gput067 CANCELLED AT 2026-02-16T11:44:14 DUE to SIGNAL Terminated ***
