{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3ca1c3",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from torch.utils.data import ConcatDataset, DataLoader, random_split\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from shaft_force_sensing import ForceSensingDataset\n",
    "from shaft_force_sensing.models import LitTransformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3bc7e",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "max_epochs = 30\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf97f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = [\n",
    "    'jaw_position', 'wrist_pitch_position', 'wrist_yaw_position',  'roll_position',\n",
    "    'wrist_pitch_velocity', 'wrist_yaw_velocity', 'jaw_velocity', 'roll_velocity',\n",
    "    'wrist_pitch_effort', 'wrist_yaw_effort', 'roll_effort',\n",
    "    'jaw_effort', 'insertion_effort', 'yaw_effort', 'pitch_effort',\n",
    "    'tx', 'ty', 'tz', 'fx', 'fy', 'fz'\n",
    "]\n",
    "t_cols = ['ati_fx', 'ati_fy', 'ati_fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c69f0e",
   "metadata": {},
   "source": [
    "# Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b479cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = sorted(Path(\"../data\").rglob(\"*.csv\"))\n",
    "\n",
    "groups = defaultdict(list)\n",
    "for p in data_paths:\n",
    "    groups[p.parent.name].append(p)\n",
    "\n",
    "test_paths = [lst[-1] for lst in groups.values()]\n",
    "train_paths = [p for p in data_paths if p not in test_paths]\n",
    "train_paths.pop(3);\n",
    "train_paths.pop(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a1cd8",
   "metadata": {},
   "source": [
    "Nomalize the target forces using a global scaler fitted on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b06406",
   "metadata": {},
   "outputs": [],
   "source": [
    "golbal_scaler = StandardScaler()\n",
    "forces = []\n",
    "for p in tqdm(train_paths):\n",
    "    data = np.loadtxt(p, delimiter=\",\", skiprows=1)\n",
    "    forces.append(data[:, -3:])\n",
    "forces = np.concatenate(forces, axis=0)\n",
    "golbal_scaler.fit(forces);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7f46e",
   "metadata": {},
   "source": [
    "Training set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180094ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = defaultdict(list)\n",
    "for p in tqdm(train_paths):\n",
    "    stride = 5\n",
    "    if p.parent.name == 'Free':\n",
    "        stride *= 4\n",
    "    dataset = ForceSensingDataset(\n",
    "        p, i_cols, t_cols,\n",
    "        stride, nomalizer=golbal_scaler)\n",
    "    train_sets[p.parent.name].append(dataset)\n",
    "\n",
    "train_set = ConcatDataset(\n",
    "    list(chain.from_iterable(train_sets.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be506a9d",
   "metadata": {},
   "source": [
    "Test set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = defaultdict(list)\n",
    "for p in tqdm(test_paths):\n",
    "    stride = 1\n",
    "    dataset = ForceSensingDataset(\n",
    "        p, i_cols, t_cols,\n",
    "        stride, nomalizer=golbal_scaler)\n",
    "    test_sets[p.parent.name].append(dataset)\n",
    "\n",
    "test_set = ConcatDataset(\n",
    "    list(chain.from_iterable(test_sets.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f48d72",
   "metadata": {},
   "source": [
    "Ratio check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group, dsets in test_sets.items():\n",
    "#     test_sets[group] = ConcatDataset(dsets)\n",
    "\n",
    "# total_samples = sum(len(dsets) for dsets in test_sets.values())\n",
    "# for group, dsets in test_sets.items():\n",
    "#     print(f\"{group}: {len(dsets)} samples, {len(dsets)/total_samples*100:.2f}%\")\n",
    "# print(f\"Total: {total_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f678b3",
   "metadata": {},
   "source": [
    "Validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "train_set, val_set = random_split(train_set, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af4a46",
   "metadata": {},
   "source": [
    "Set up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e10bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17809174",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66065e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitTransformer(\n",
    "    input_size=len(i_cols),\n",
    "    force_output_size=len(t_cols),\n",
    "    d_model=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    nhead=num_heads,\n",
    "    lr=learning_rate,\n",
    "    data_mean=golbal_scaler.mean_,\n",
    "    data_std=golbal_scaler.scale_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e848e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"../logs\") / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbfe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Checkpoint to save best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=save_dir,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    filename=\"best-epoch-{epoch:02d}-val_loss-{val_loss:.4f}\"\n",
    ")\n",
    "\n",
    "# TensorBoard logger\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir,\n",
    "    name=\"transformer_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc497736",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "differentiable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
