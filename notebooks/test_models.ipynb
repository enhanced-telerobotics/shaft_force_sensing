{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3ca1c3",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af540916",
   "metadata": {},
   "source": [
    "## Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "from torch.utils.data import ConcatDataset, DataLoader, random_split\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "from shaft_force_sensing import ForceSensingDataset\n",
    "from shaft_force_sensing.models import LitTransformer\n",
    "from shaft_force_sensing.evaluation import (\n",
    "    tb_to_numpy,\n",
    "    add_norm,\n",
    "    array_bais,\n",
    "    array_medfilt,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3bc7e",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "max_epochs = 30\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf97f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = [\n",
    "    'jaw_position', 'wrist_pitch_position', 'wrist_yaw_position',  'roll_position',\n",
    "    'wrist_pitch_velocity', 'wrist_yaw_velocity', 'jaw_velocity', 'roll_velocity',\n",
    "    'wrist_pitch_effort', 'wrist_yaw_effort', 'roll_effort',\n",
    "    'jaw_effort', 'insertion_effort', 'yaw_effort', 'pitch_effort',\n",
    "    'tx', 'ty', 'tz', 'fx', 'fy', 'fz'\n",
    "]\n",
    "t_cols = ['ati_fx', 'ati_fy', 'ati_fz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c69f0e",
   "metadata": {},
   "source": [
    "## Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b479cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = sorted(Path(\"../data\").rglob(\"*.csv\"))\n",
    "\n",
    "groups = defaultdict(list)\n",
    "for p in data_paths:\n",
    "    groups[p.parent.name].append(p)\n",
    "\n",
    "test_paths = [lst[-1] for lst in groups.values()]\n",
    "train_paths = [p for p in data_paths if p not in test_paths]\n",
    "train_paths.pop(3);\n",
    "train_paths.pop(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a1cd8",
   "metadata": {},
   "source": [
    "Nomalize the target forces using a global scaler fitted on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b06406",
   "metadata": {},
   "outputs": [],
   "source": [
    "golbal_scaler = StandardScaler()\n",
    "forces = []\n",
    "for p in tqdm(train_paths):\n",
    "    data = np.loadtxt(p, delimiter=\",\", skiprows=1)\n",
    "    forces.append(data[:, -3:])\n",
    "forces = np.concatenate(forces, axis=0)\n",
    "golbal_scaler.fit(forces);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17809174",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7f46e",
   "metadata": {},
   "source": [
    "Training set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180094ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = defaultdict(list)\n",
    "for p in tqdm(train_paths):\n",
    "    stride = 5\n",
    "    if p.parent.name == 'Free':\n",
    "        stride *= 4\n",
    "    dataset = ForceSensingDataset(\n",
    "        p, i_cols, t_cols,\n",
    "        stride, nomalizer=golbal_scaler)\n",
    "    train_sets[p.parent.name].append(dataset)\n",
    "\n",
    "train_set = ConcatDataset(\n",
    "    list(chain.from_iterable(train_sets.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f48d72",
   "metadata": {},
   "source": [
    "Ratio check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group, dsets in test_sets.items():\n",
    "#     test_sets[group] = ConcatDataset(dsets)\n",
    "\n",
    "# total_samples = sum(len(dsets) for dsets in test_sets.values())\n",
    "# for group, dsets in test_sets.items():\n",
    "#     print(f\"{group}: {len(dsets)} samples, {len(dsets)/total_samples*100:.2f}%\")\n",
    "# print(f\"Total: {total_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f678b3",
   "metadata": {},
   "source": [
    "Validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "train_set, val_set = random_split(train_set, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af4a46",
   "metadata": {},
   "source": [
    "Set up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e10bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c7583",
   "metadata": {},
   "source": [
    "Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66065e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitTransformer(\n",
    "    input_size=len(i_cols),\n",
    "    force_output_size=len(t_cols),\n",
    "    d_model=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    nhead=num_heads,\n",
    "    lr=learning_rate,\n",
    "    data_mean=golbal_scaler.mean_,\n",
    "    data_std=golbal_scaler.scale_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e848e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"../logs\") / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbfe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Checkpoint to save best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=save_dir,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    filename=\"best-epoch-{epoch:02d}-val_loss-{val_loss:.4f}\"\n",
    ")\n",
    "\n",
    "# TensorBoard logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir,\n",
    "    name=\"transformer_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc497736",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c6a04",
   "metadata": {},
   "source": [
    "Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b71c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"../logs\") / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_path = sorted(Path(\"../logs/20260212_150853\").glob(\"best*.ckpt\"))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba577db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitTransformer.load_from_checkpoint(\n",
    "    ckpt_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be506a9d",
   "metadata": {},
   "source": [
    "Test set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea769b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "golbal_scaler = StandardScaler()\n",
    "golbal_scaler.mean_ = model.model.data_mean.numpy(force=True)\n",
    "golbal_scaler.scale_ = model.model.data_std.numpy(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = dict()\n",
    "\n",
    "for p in tqdm(test_paths):\n",
    "    dataset = ForceSensingDataset(\n",
    "        p, i_cols, t_cols,\n",
    "        nomalizer=golbal_scaler)\n",
    "    test_sets[p.parent.name] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b72899",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = {group: DataLoader(dset, batch_size=1000, shuffle=False)\n",
    "                for group, dset in test_sets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d66d5c",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, loader in test_loaders.items():\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir,\n",
    "        name=\"transformer_test\",\n",
    "        version=group\n",
    "    )\n",
    "\n",
    "    Trainer(\n",
    "        logger=logger\n",
    "    ).test(\n",
    "        model=model,\n",
    "        dataloaders=loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9c106",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"../logs\") / \"20260212_155802\" / \"transformer_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f517ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['F_x', 'F_y', 'F_z', 'Norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a6645",
   "metadata": {},
   "source": [
    "## Single set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "path = list(save_dir.glob(\"*\"))[idx]\n",
    "gt, pred = tb_to_numpy(path)\n",
    "path.stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27eb1d",
   "metadata": {},
   "source": [
    "Denormlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = golbal_scaler.inverse_transform(gt)\n",
    "pred = golbal_scaler.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131d6a8",
   "metadata": {},
   "source": [
    "Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = array_medfilt(pred, kernel_size=71)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d60ad2",
   "metadata": {},
   "source": [
    "Zero offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = array_bais(pred, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f8aca",
   "metadata": {},
   "source": [
    "Add norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b35400",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = add_norm(gt)\n",
    "pred = add_norm(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea25d6",
   "metadata": {},
   "source": [
    "Time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gt.shape[1]\n",
    "fig = make_subplots(rows=d, cols=1, shared_xaxes=True, subplot_titles=axes)\n",
    "\n",
    "for i, name in enumerate(axes, start=1):\n",
    "    fig.add_trace(go.Scatter(y=gt[:, i-1], mode=\"lines\", name=f\"{name} (gt)\"), row=i, col=1)\n",
    "    fig.add_trace(go.Scatter(y=pred[:, i-1], mode=\"lines\", name=f\"{name} (pred)\"), row=i, col=1)\n",
    "\n",
    "fig.update_layout(height=250 * d, title=\"Ground Truth vs Prediction\", showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdee626",
   "metadata": {},
   "source": [
    "## Loop all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "for path in tqdm([_ for _ in save_dir.iterdir() if _.is_dir()]):\n",
    "    group = path.stem\n",
    "\n",
    "    # Load data\n",
    "    gt, pred = tb_to_numpy(path)\n",
    "\n",
    "    # Post-processing\n",
    "    gt = golbal_scaler.inverse_transform(gt)\n",
    "    pred = golbal_scaler.inverse_transform(pred)\n",
    "\n",
    "    pred = array_medfilt(pred, kernel_size=71)\n",
    "    pred = array_bais(pred, 50)\n",
    "\n",
    "    gt = add_norm(gt)\n",
    "    pred = add_norm(pred)\n",
    "\n",
    "    data[group] = (gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49989a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all = np.concatenate([data[group][0] for group in data], axis=0)\n",
    "pred_all = np.concatenate([data[group][1] for group in data], axis=0)\n",
    "data['All'] = (gt_all, pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f07bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, (gt, pred) in data.items():\n",
    "    # Metrics\n",
    "    gt_min = np.min(gt, axis=0)\n",
    "    gt_max = np.max(gt, axis=0)\n",
    "    gt_range = gt_max - gt_min\n",
    "    rmse = root_mean_squared_error(gt, pred, multioutput='raw_values')\n",
    "    nrmse = rmse / gt_range\n",
    "    r2_scores = r2_score(gt, pred, multioutput='raw_values')\n",
    "\n",
    "    # Logging\n",
    "    with open(save_dir / f\"metrics.txt\", \"a\") as f:\n",
    "        print(f\"Group: {group}\", file=f)\n",
    "        for i, name in enumerate(axes):\n",
    "            print(\n",
    "                f\"{name}: \\\n",
    "                Range={gt_range[i]:.4f}, \\\n",
    "                RMSE={rmse[i]:.4f}, \\\n",
    "                NRMSE={nrmse[i]*100:.2f}%, \\\n",
    "                R2={r2_scores[i]*100:.2f}\",\n",
    "                file=f)\n",
    "        print(\"-\" * 10, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "differentiable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
